{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonnegative Matrix Factorization\n",
    "This scenario factorizes an $N \\times M$ matrix $X$ into a rank-$K$ approximation $WH$, where $W$ is $N \\times K$, $H$ is $K \\times M$ and all values in the matrices are nonnegative. Each value in $W$ and $H$ can be initialized randomly to a positive number, e.g., from a `Uniform(1,2)`distribution.\n",
    "\n",
    "The data to be used for this problem consists of 8447 documents from $\\textit{The New York Times}$. The vocabulary size is 3012 words. First need to use this data to construct the matrix $X$, where $X_{ij}$ is the number of times word $i$ appears in document $j$. Therefore, $X$ is $3012 \\times 8447$ and most values in $X$ will equal zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 1:\n",
    "> Implement and run the NMF algorithm on this data using the $\\textit{divergence penalty}$. Set the rank to 25 and run for 100 iterations. This corresponds to learning 25 topics. Plot the objective as a function of iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|![](images/fig1.png)|\n",
    "|:---:|\n",
    "|Divergence objective of NMF by iterations|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 2:\n",
    "> After running the algorithm, normalize the columns of $W$ so they sum to one. For each column of $W$, list the 10 words having the largest weight and show the weight. The $i$th row of $W$ corresponds to the $i$th word in the “dictionary” provided with the data. Organize these lists in a $5 \\times 5$ table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|![](images/fig2.png)|\n",
    "|:---:|\n",
    "|Words for topics|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('ml': conda)",
   "language": "python",
   "name": "python37664bitmlconda706340e93e3048b4937743173be114e4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
