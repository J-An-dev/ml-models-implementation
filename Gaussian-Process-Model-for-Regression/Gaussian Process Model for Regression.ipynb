{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process Model for Regression\n",
    "This scenario analyzes data using the Gaussian Process Model for Regression. The goal of the problem is to **predict the miles per gallon a car will get** using six quantities (features) about that car. The data is broken into training and testing sets. Each row in both “$X$” files contain six features for a single car (plus a 1 in the 7th dimension) and the same row in the corresponding “$y$” file contains the miles per gallon for that car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gaussian process treats a set of $N$ observations $(x_1,y_1),...,(x_N,y_N)$, with $x_i \\in \\mathbb{R}^d$ and $y_i \\in \\mathbb{R}$, as being generated from a multivariate Gaussian distribution as follows,\n",
    "\\begin{equation}\n",
    "\ty \\sim Normal(0,\\sigma^2 I+K), \\text{    } K_{ij}=k(x_i,x_j) \\text{    } \\left(\\text{use: exp}\\{-\\frac{1}{b} \\Vert x_i-x_j \\Vert ^2 \\} \\right)\n",
    "\\end{equation}\n",
    "Here, $y$ is an $N$-dimensional vector of outputs and $K$ is an $N \\times N$ kernel matrix. For this problem use the Gaussian kernel indicated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 1:\n",
    "> Write code to implement the Gaussian process and to make predictions on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When given $N$ observation pairs $\\mathcal{D} = \\{(x_i,y_i)\\}_{i=1}^N$ and want to predict $y_0$ given $x_0$. Integrating out $w$ and setting $\\lambda = 1$, the joint distribution is \n",
    "\\begin{equation}\n",
    "\t\\left[ \\begin{array}{cc} y_0 \\\\ y \\end{array} \\right] \\sim Normal \\left(\\mathbf{0}, \\sigma^2 \\mathbf{I} + \\left[ \\begin{array}{cc} x_0^T x_0 & (Xx_0)^T \\\\ Xx_0 & XX^T \\end{array} \\right] \\right)\n",
    "\\end{equation}\n",
    "Then, to predict $y(x)$ given $\\mathcal{D}$ and new $x$, the calculation can be showed as:\n",
    "\\begin{equation}\n",
    "\ty(x)|\\mathcal{D} \\sim Normal(\\mu(x), \\Sigma (x))\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\t\\mu(x) = (Xx)^T(\\sigma^2 \\mathbf{I} + XX^T)^{-1}y = K(x, \\mathcal{D})(\\sigma^2 \\mathbf{I} + K_n)^{-1}y\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\t\\Sigma (x) & = \\sigma^2 + x^Tx - (Xx)^T(\\sigma^2 \\mathbf{I} + XX^T)^{-1}(Xx)\\\\\n",
    "\t&  = \\sigma^2 + K(x,x) - K(x, \\mathcal{D})(\\sigma^2 \\mathbf{I} + K_n)^{-1}K(x,\\mathcal{D})^T\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "Where $K(x,\\mathcal{D}) = [K(x,x_1),...,K(x,x_n)]$ and $K_n$ is the $n \\times n$ kernel matrix restricted to points in $\\mathcal{D}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 2:\n",
    "> For $b \\in \\{5,7,8,11,13,15 \\}$ and $\\sigma^2 \\in \\{ .1,.2,.3,.4,.5,.6,.7,.8,.9,1\\}$ (60 total pairs $(b,\\sigma^2)$) calculate the RMSE on the 42 test points. Use the mean of the Gaussian process at the test point as prediction. Show results in a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE values for 60 different pairs are showed in the table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|![](images/table.png)|\n",
    "|:---:|\n",
    "|RMSE values for 60 different pairs|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> Which value was the best and how does this compare with the result using Polynomial Regression method? What might be a drawback of the approach in this method (as given) compared with Polynomial Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among these 60 pairs, when select $b=11$ and $\\sigma^2=0.1$ giving the lowest RMSE value 1.8945, which is smaller than the optimal value in the Polynomial Regression method. In the Polynomial Regression method when choose the polynomial order $p = 3$ with a particular value of $\\lambda$ at 52 gives the lowest RMSE value 2.0999.\n",
    "\n",
    "A drawback is that we lose interpretability of the model. Before we had weights on the features, so we knew how the inputs impacted the outputs. Now we don’t have that information. The GP model only helps us make better predictions. Another drawback is that as we get more data the matrix we have to invert increases in size with the GP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 3:\n",
    "> To better understand what the Gaussian Process is doing through visualization, re-run the algoalgorithm by using *only* the 4th dimension of $x_i$ (car weight). Set $b=5$ and $\\sigma^2=2$. Show a scatter plot of the data ($x[4]$ versus y for each point). Also, plot as a solid line the predictive mean of the Gaussian Process at each point *in the training set*. You can think of this problem as asking you to create a test set by duplicating $x_i[4]$ for each $i$ in the training set and then to predict that test set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plot and the line for predictive means of the Gaussian Process is showed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|![image.png](images/GP.png)|\n",
    "|:---:|\n",
    "|Prediction for the 4th dimension of $x_i$|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('ml': conda)",
   "language": "python",
   "name": "python37664bitmlconda706340e93e3048b4937743173be114e4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
