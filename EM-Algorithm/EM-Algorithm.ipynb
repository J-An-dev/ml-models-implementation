{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM Algorithm\n",
    "\n",
    "This problem implements the EM algorithm for the Gaussian mixture model, with the purpose of using it in a Bayes classifier. The data is a processed version of the spam email data used in [k-NN problem](https://github.com/J-An-dev/ml-models-implementation/blob/master/k-NN-Classifier/k-NN-Classifier.ipynb). Now, each labeled pair $(x,y)$ has $x \\in \\mathbb{R}^{10}$. In this problem, the class conditional density will be the Gaussian mixture model (GMM). In these experiments, all covariance matrices are initialized to the empirical covariance of the data being modeled. Also randomly initialize the means by sampling from a single multivariate Gaussian where the parameters are the mean and covariance of the data being modeled. The mixing weights are initialized to be uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 1:\n",
    "> Implement the EM algorithm for the GMM. Using the training data provided, for each class separately, plot the log marginal objective function for a 3-Gaussian mixture model over 10 different runs and for iterations 5 to 30. There should be two plots, each with 10 curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|![](images/EM1.png)|![](images/EM2.png)|\n",
    "|:---:|:---:|\n",
    "|3-GMM Class 1 log marginal objective function by iterations|3-GMM Class 0 log marginal objective function by iterations|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 2:\n",
    "> Using the best run for each class after 30 iterations, predict the testing data using a Bayes classifier and show the result in a $2 \\times 2$ confusion matrix, along with the accuracy percentage. Repeat this process for a 1-, 2-, 3- and 4-Gaussian mixture model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction results for each GMM are showed below, where $y$ stands for ground truth class and $y'$ stands for preticted class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1-GMM Prediction: 77.39$\\%$ prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||$y = 1$|$y = 0$|\n",
    "|:--:|:--:|:--:|\n",
    "|$y' = 1$|176|98|\n",
    "|$y' = 0$|6|180|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2-GMM Prediction: 80.00$\\%$ prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||$y = 1$|$y = 0$|\n",
    "|:--:|:--:|:--:|\n",
    "|$y' = 1$|177|87|\n",
    "|$y' = 0$|5|191|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3-GMM Prediction: 81.52$\\%$ prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||$y = 1$|$y = 0$|\n",
    "|:--:|:--:|:--:|\n",
    "|$y' = 1$|175|78|\n",
    "|$y' = 0$|7|200|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 4-GMM Prediction: 81.30$\\%$ prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||$y = 1$|$y = 0$|\n",
    "|:--:|:--:|:--:|\n",
    "|$y' = 1$|175|79|\n",
    "|$y' = 0$|7|199|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('ml': conda)",
   "language": "python",
   "name": "python37664bitmlconda706340e93e3048b4937743173be114e4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
